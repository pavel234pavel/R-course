---
title: 'Семинар 6. Регрессия + маркдаун'
date: '22 октября 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: journal-of-econometrics.csl
---



Шаманское заклинание для настройки глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
# Регрессия при гомоскедастичных ошибках

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(sjstats) # удобные мелкие функции для работы с моделями
library(sandwich) # оценка Var для гетероскедастичности
library(AER) # работа с инструментальными переменными
library(Ecdat) # много-много разных наборов данных
library(huxtable) # красивые таблички в html, tex
library(stargazer) # красивые таблички в html, tex
library(texreg) # и снова красивые таблички в html, tex :)
library(estimatr) # модели с робастными ошибками
```

Возьмём набор данных об изменении пульса студентов до и после упражнений.
Его описание доступно по [ссылке](http://www.statsci.org/data/oz/ms212.html).

Загрузим данные и посмотрим на описательные статистики.

Установите в качестве текущей папки ту папку, где лежит данный `.Rmd`-файл:
`Session` — `Set working directory` — `To source file location`.

Правильно укажите путь к данным относительно `.Rmd`-файла:

```{r}
pulse <- import("data/pulse.txt")
skim(pulse)

```

- Сколько в данных наблюдений? Сколько переменных?
- Какие переменные на самом деле являются факторными?

Вернём факторным переменным положенный статус!

```{r}
pulse_fct = pulse %>% mutate(Gender = factor(Gender), 
                             Alcohol = factor(Alcohol))
pulse_fct <- pulse %>%
  mutate_at(vars(-Weight, -Height, -Age, -Pulse1, -Pulse2), factor)
```

И теперь можно приступать к регрессиям.
Начнём с парной и построим регрессию пульса после упражнений `Pulse2` на константу и пульс до упражнений `Pulse1`.
Для этого воспользуемся командой `lm()` и передадим ей данные и формулу.

```{r}
model_r <- lm(data = pulse_fct, Pulse2 ~ Pulse1)
```

С помощью команды `summary()` посмотрим на описание модели.

```{r}
summary(model_r)
```

- На сколько в среднем отличается пульс после упражнений у двух студентов, если
пульс до упражнений у них отличается на единицу?
- Какие коэффициенты значимы?
- Какая доля разброса пульса после упражнений объясняется пульсом до упражнений?

* Упражнение 1.

Упражнения будем выполнять на встроенном наборе данных `Housing`.
Посмотрите описание переменных в справке :)
Затем «бросьте взгляд» на данные, есть ли в них факторные переменные, которые объявлены иначе?

```{r}
house <- Housing
# ___
```

Постройте парную регрессию цены дома `price` на константу и площадь дома `lotsize`.

```{r}
# house_r <- lm(data = ___, ___ ~ ___)
# summary(___)
```

- Совпадает ли знак коэффициента при `lotsize` с ожидаемым?
- Можно ли считать коэффициента при `lotsize` значимым на уровне 1\%?


Другой способ посмотреть на описание модели — воспользоваться функциями пакета `broom`.
Оценки коэффциентов, стандартные ошибки, p-значения выводит команда `tidy()`:
```{r}
tidy(model_r)
```


А функция `glance()` покажет общие характеристики модели, для которых достаточно одной строчки, — коэффциент детерминации, значение лог-функции правдоподобия, AIC, BIC...

```{r}
glance(model_r)

```
Если из общей таблицы описания модели нужна только информация о коэффициентах, то поможет команда `coeftest()` из пакета `lmtest()`.

```{r}
coeftest(model_r)
```

Нарисуем линию регрессии для модели, в которой зависимая переменная — это пульс после упражнений, а объясняющая — пульс до упражнений.
Для этого к диаграмме рассеяния добавим дополнительный слой `geom_smooth()`.
Внутри него за линейную регрессию отвечает `method = "lm"`.

```{r}
ggplot(data = pulse_fct, aes(x = Pulse1, y = Pulse2)) +
  geom_point() +
  geom_smooth(method = "lm")
```

* Упражнение 2.

Визуализируйте линию регрессии для модели `house_r`.
В ней зависимой переменной была цена дома `price`, а объясняющей — площадь `lotsize`.

```{r}
# ggplot(data = ___, aes(x = ___, y = ___)) +
#   ___() +
#   geom_smooth(method = ___)
```

Теперь оценим более сложную модель.
К объясняющим переменным добавим вес студента `Weight` и бинарные переменные `Ran`, где 2 соответствует студенту, который выполнял упражнения , и `Smokes`, где значение 2 — это студент-курильщик.

```{r}
model_ur <- lm(data = pulse_fct, Pulse2 ~ Weight + Pulse1 + Ran + Smokes)
summary(model_ur)
```

* Упражнение 3.

Оцените более сложную модель для набора данных о домах.
Среди объясняющих переменных укажите площадь дома `lotsize`, количеcтво спален `bedrooms`
и бинарную переменную `prefarea`, которая равна 1 для домов, расположенных в хороших районах.

```{r}
# house_ur <- lm(data = ___, ___ ~ ___)
# summary(___)
```

Есть ли проблемы у модели?
Диагностический график в студию!

```{r}
ggnostic(model = model_ur)
pulse_augmented = augment(model_ur, pulse_fct)
filter(pulse_augmented, .cooksd > 0.6)
```

На этом графике четыре линии!
* Первая: зависимость величины остатка $\hat u_i = y_i - \hat y_i$ от каждого регрессора.
* Вторая: зависимость величины $\hat \sigma_i$ от каждого регрессора.

Величина $\hat \sigma_i$ показывает, какой была бы оценка стандартного отклонения случайной составляющей,
если бы $i$-ое наблюдение выкинули из модели.

Слишком маленькие значения $\hat \sigma_i$ говорят о том, что
при выкидывании наблюдения резко падает оценка стандартного отклонения. Значит, наблюдение могло быть выбросом.

* Третья: зависимость величины $h_{ii}$ от каждого регрессора.

Величина $h_{ii}$ имеет две интерпретации. Во-первых, она показывает, насколько изменится прогноз $\hat y_i$ при увеличении фактического наблюдения $y_i$ на единицу.
Во-вторых, эта величина показывает отношение дисперсии прогноза $\hat y_i$ к дисперсии случайной составляющей:
\[
h_{ii} = \frac{Var(\hat y_i)}{Var(u_i)}
\]

* Четвертая: зависимость расстояния Кука от каждого из регрессоров.

Расстояние Кука показывает, насколько сильно изменятся прогнозы по всему набору данных, при выкидывании $i$-го наблюдения,

\[
D_i = \frac{\sum_{j=1}^n(\hat y_j - \hat y_j^{(-i)})^2}{k\hat\sigma^2},
\]
где $k$ — число регрессоров, считая единичный столбец.

Подробнее про расстояние Кука можно прочитать в маленьких [заметках](http://bdemeshev.github.io/r_cycle/cycle_files/02_ols_oranges.html).

- Какие наблюдения являются потенциальными выбросами?

Построим 5\%-ые доверительные интервалы для всех коэффициентов модели `model_ur`.
Для этого будем использовать команду `coefci()`.
Поменять уровень значимости можно аргументом `level`.
Затем визуализируем получившиеся доверительные интервалы командой `sjp.lm()` из пакета `sjPlot`.

```{r}
coefci(model_ur)
plot_model(model_ur, ci.lvl = 0.9)
```

- Загляните в справку :) Какая опция функции `coefci` отвечает за уровень доверия?

* Упражнение 4.

Постройте 95\%-ные доверительные интервалы для всех коэффициентов модели `house_ur`
и визуализируйте их.

```{r}
# coefci(___)
# plot_model(___, ci.lvl = ___)
```


Если есть две вложенных модели, то есть одна является частным случаем другой,
то можно провести тест Вальда, чтобы выбрать одну из них.

$H_0$: верна ограниченная (короткая) модель;

$H_a$: верная неограниченная (длинная) модель;

```{r}
waldtest(model_r, model_ur)
```

Сравниваем p-значение с уровнем значимости.

* Упражнение 5.

Проведите тест Вальда для  моделей `house_r` и `huose_ur`.

```{r}
# waldtest(___, ___)
```

- Какую модель следует выбрать по результатам теста на 5\%-ом уровне значимости?


# О бедном t-тесте замолвите слово!

Иногда душа хочет проверки самых простых гипотез!

Если хочется построить доверительный интервал для математического ожидания пульса до упражнений,
то достаточно построить регрессию на константу:

```{r}
model_mu <- lm(data = pulse_fct, Pulse1 ~ 1)
coefci(model_mu)
```

Если хочется построить доверительный интервал для разности математического ожидания пульса у курящих и некурящих,
то можно построить регрессию на константу и дамми-переменную.

```{r}
model_diff <- lm(data = pulse_fct, Pulse1 ~ Smokes)
coefci(model_diff)
```

* Упражнение 6.

Постройте доверительный интервал для математического ожидания цены и
доверительный интервал для разности математических ожиданий цены дома в хорошем и обычном районе.

```{r}
# house_mu <- lm(data = ___, ___ ~ ___)
# summary(___)

# house_diff <- lm(data = ___, ___ ~ ___)
# summary(___)
```

Дисперсионный анализ легким движением руки также заменяется на построение единственной регрессии.

Проверим, что две качественные переменные, `Smokes` и  `Gender`, не оказывают влияния на частоту пульса.


```{r}
model_2anova <- lm(data = pulse_fct, Pulse1 ~ Smokes * Gender)
summary(model_2anova)
anova_stats(model_2anova)
```

* Упражнение 7.

Проверьте, что наличие подъезда к дому `driveway` и расположение в хорошем районе `prefarea`,
не влияют на цену дома.

```{r}
# house_2anova <- lm(data = ___, ___ ~ ___ * ___)
# summary(___)
```


# Регрессия при гетероскедастичных ошибках

Если не предполагать, что дисперсии ошибок $Var(u_i)$ одинаковы для всех наблюдений,
то построенные нами доверительные интервалы и выполненная проверка гипотез — полный отстой :)


Повторяем табличку с тестами на значимость отдельных коэффициентов с учётом поправки на гетероскедастичность.

```{r}
coeftest(model_ur, vcov. = vcovHC)
```

Также легко получить доверительные интервалы:

```{r}
coefci(model_ur, vcov. = vcovHC)
```

Результаты в R чуть отличаются от результатов в stata.
По-умолчанию, R использует корректировку HC3 для подсчёта стандартных ошибок коэффициентов, а stata — менее удачную, устаревшую HC1.
Сравнение есть у [Achim Zeileis](https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf).
Если хочется воспроизвести именно корректировку HC1, то запросто :)

```{r}
coeftest(model_ur, vcov. = vcovHC(model_ur, type = "HC1"))
```

Сравним две вложенных модели с учётом поправки на гетероскедастичность:
```{r}
waldtest(model_r, model_ur, vcov = vcovHC)
```

* Упражнение 8.

Получите таблицу с тестами на значимость коэффициентов в модели `house_ur`,
используя корректировку `HC3`.
А затем сравните две модели `house_r` и `house_ur` с учётом поправки на гетероскедастичность.

```{r}
# coeftest(___, vcov. = ___, type = ____)
# waldtest(___, ___, vcov =  vcovHC)
```

Вторая вариация: переоценка модели.
```{r}
model_r_rob <- 
  lm_robust(data = pulse_fct, Pulse2 ~ Pulse1)
model_ur_rob <- 
  lm_robust(data = pulse_fct, 
    Pulse2 ~ Weight + Pulse1 + Ran + Smokes)
summary(model_ur_rob)
```

Тест Вальда:
```{r}
waldtest(model_r_rob, model_ur_rob)
# waldtest(model_r, model_ur_rob)
```


# Инструментальные переменные


Исследователи всегда мечтают обнаружить не просто статистическую связь, а причинно-следственную.
Проще всего было бы обнаружить связь с помощью рандомизированного эксперимента:
поделить случайно индивидов случайно на две группы, одну попросить стирать обычным порошком,
а вторую — новым чудопорошком.
Важно упаковать порошки совершенно одинаково и говорить одни и те же слова :)

Мы часто имеем с данными наблюдений.
Рандомизированного эксперимента при этом не было.
В редких случаях можно попытаться обнаружить причинно-следственную связь на данных наблюдений.

Рассмотрим набор данных по предложению труда женщин `Mroz` из пакета `Ecdat`.

```{r}
glimpse(Mroz)
```

Отберём работавших женщин.
```{r}
labor <- filter(Mroz, wagew > 0)
```
Мы хотим оценить причинно-следственный эффект от дополнительного года обучения на заработную плату женщины.

На первый взгляд разумно попробовать обычный МНК:
```{r}
model_lm <- lm(data = labor, log(wagew) ~ educw + experience + I(experience^2))
summary(model_lm)
```

Эта регрессия прекрасно оценивает силу статистической взаимосвязи и показывает,
насколько различается зарплата двух женщин, у которых разное образование, и одинаковый опыт работы.

Эта регрессия вовсе не говорит, насколько увеличится зарплата данной женщины,
если она надумает ещё год поучиться.

Проблема состоит в ненаблюдаемых характеристиках, например, в способностях жещнины.
Логично предположить, что ненаблюдаемые способности связаны положительно и с зарплатой
и с продолжительностью обучения.

При всей спорности предположения, будем считать, что
\[
\log(wagew_i) = \beta_1 + \beta_2 educw_i + \beta_3 experience_i +
   \beta_4 experience_i^2 + \beta_5 ability_i + u_i,
\]
где ошибка $u_i$ некоррелирована с остальными переменными в правой части.


Предположим, что образование матери и отца, `educwm` и `educwf` не коррелированы с ошибкой $u_i$.
Тогда их можно использовать как инструменты для переменной `educw_i`.


В качестве инструментальных переменных для `educw` возьмём образование матери и отца, `educwm` и `educwf`:

```{r}
model_iv <- ivreg(data = labor,
  log(wagew) ~ educw + experience + I(experience^2) |
    experience + I(experience^2) + educwm + educwf)
summary(model_iv, diagnostics = TRUE)
```


```{r}
lm(data = pulse_fct, Pulse2 ~ (Smokes + Pulse1 + Ran)^3)
```


После вертикальной палочки `|` в команде `ivreg` указывают экзогенные переменные,
используемые в качестве инструментов.

Если верить в то, что образование матери и отца некоррелировано с ненаблюдаемыми способностями женщины,
тогда коэффициент при образовании женщины `educw` показывает, насколько
изменится зарплата женщины при увеличении образования на один год, постоянном опыте и постоянных способностях.

Автоматически команда `summary` с опцией `diagonostics = TRUE` проводит три теста:

1. Тест на слабые инструменты

Нулевая гипотеза: $H_0$: инструментальные переменные не коррелированы с потенциально эндогенным регрессором

2. Тест Хаусмана на равенство оценок IV и обычного МНК.

Нулевая гипотеза: $H_0$: ковариация потенциально эндогенного регрессора с ошибкой равна нулю.

3. Тест Саргана

Нулевая гипотеза: $H_0$:  инструментальные переменные правильно подобраны, то есть
они не коррелированы с ошибкой, а невключённые инструменты и не должны быть включены в модель.

- Какие гипотезы отвергаются, какие не отвергаются в нашем случае?


* Упражнение 9.

Для упражнения возьмём данные о потреблении сигарет в США `CigaretteeSW` из
пакета `AER`.
Его описание можно прочесть в справке!

Возьмём наблюдения только за 1995 год и создадим несколько новых переменных:
логарифм реальных цен `lrprice`, логарифм дохода на душу населения `lrincome`,
логарифм количества пачек сигарет на человека `lquant` и реальный налог на
сигареты `tdiff`.

```{r}
data("CigarettesSW")
cig <- subset(CigarettesSW, year == 1995)
cig$lrprice <- log(cig$price / cig$cpi)
cig$lrincome <- log(cig$income / cig$population / cig$cpi)
cig$lquant <- log(cig$packs)
cig$tdiff <- (cig$taxs - cig$tax) / cig$cpi

# glimpse(___)
# skim(___)
```

Постройте регрессию логарифма количества пачек сигарет на человека `lquant`
на логарифм реальной цены одной пачки `lrprice`, используя в качестве инстурмента
реальный налог `tdiff`.

```{r}
# cig_iv1 <- ivreg(data = ___, ___ ~ ___ | ___)
# summary(___, diagnostics = ___)
```

Добавьте к объясняющим переменным логарифм реального дохода на душу населения
`lrincome`, а к инструментам — реальный налог на сигареты `tax / cpi`.

```{r}
# cig_iv2 <- ivreg(data = ___, ___ ~ ___ + ___ | ____ + ___ + I(tax/cpi))
# summary(___, ___ = ___)
```

# Формат html

Прелесть html состоит в богатстве оформления и динамических элементах.

Начнём с нескольких таблиц.

Составим по-быстрому табличку описательных статистик:
```{r, results="asis"}
skim_to_wide(diamonds) %>%
  filter(type != "factor") %>%
  select(variable, complete, mean, sd, p0, p50, hist) %>%
  hux(add_colnames = TRUE) %>% print_html()
```

Оформляем наши таблички симпатичнее:
```{r, results="asis"}
htmlreg(list(model_r, model_ur, model_r_rob, model_ur_rob),
        include.ci = FALSE,
        star.symbol = "\\*")
```

Вариант с доверительными интервалами:
```{r, results="asis"}
htmlreg(list(model_r, model_ur, model_r_rob, model_ur_rob), ci.force = TRUE)
```



Просто картинка в html с подписями и ссылкой:
```{r, fig.width=3, fig.height=4}
ggplot(data = pulse_fct, aes(x = Pulse1, y = Pulse2)) +
  geom_point() +
  geom_smooth(method = "lm") + labs(x = "Пульс до (уд/мин)", y = "Пульс после (уд/мин)")
```

Для примера процитируем несколько источников,
@afanasyev92, @cobb2011teaching, @microsoftProject2008, @doe:website.

Другие стилевые заготовки для оформления цитат можно скачать в архиве [zotero](https://www.zotero.org/styles).


Примеры таблиц для html с [пакетом huxtable](https://hughjonesd.github.io/huxtable/), интерактивные элементы, например, карты, с [htmlwidgets](http://gallery.htmlwidgets.org).


И библиографию в студию:

