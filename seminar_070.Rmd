---
title: 'Семинар 7. Классификация'
author: "Винни-Пух :)"
date: "2018-10-29"
output:
  html_document: default
  pdf_document:
    toc: false
    toc_depth: 2
    keep_tex: yes
    number_sections: true
    fig_width: 4
    fig_height: 3
    fig_caption: true
    highlight: tango
    latex_engine: xelatex
  word_document: default
lang: ru-RU
mainfont: Arial
fontsize: 11pt
geometry: left=2cm, right=2cm, top=2cm, bottom=2cm
documentclass: article
linkcolor: blue
urlcolor: blue
citecolor: blue
header-includes:
- \newfontfamily{\cyrillicfonttt}{Arial}
- \newfontfamily{\cyrillicfont}{Arial}
- \newfontfamily{\cyrillicfontsf}{Arial}
editor_options: 
  chunk_output_type: console
---



Шаманское заклинание для настройки глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(Ecdat) # много-много разных наборов данных
library(ISLR) # ещё данные
library(sandwich) # оценка Var для гетероскедастичности
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
library(ranger) # строим деревья
```


Импортируем набор данных по успеваемости студентов и смотрим на него :)

```{r}
educ <- import("data/xAPI-Edu-Data.csv")
skim(educ)
```

Данные взяты с [kaggle.com](https://www.kaggle.com/aljarah/xAPI-Edu-Data/).
Целевая переменная — успеваемость студента, `Class`, принимает три значения, 'H' (high), 'M' (mid), 'L' (low).
Остальные переменные — характеристики студента.


Для целей бинарной классификации объединяем две верхних категории в одну:

```{r}
educ_logit <- mutate(educ, y = fct_collapse(Class, H = c("M", "H")))
```

И объявляем все текстовые переменные факторными:

```{r}
educ_fct <- mutate_if(educ_logit, is.character, factor)
```

Разделим выборку на две части, обучающую и тестовую.
По тестовой мы сможем оценить качество прогнозов нашей модели.

Разбиение выборки на две части — это случаная операция,
поэтому зададим на удачу зерно генератора случайных чисел.

Создадим вектор `train_rows` с номерами строк для обучающей части.

```{r}
set.seed(777)
train_rows <- createDataPartition(educ_fct$y, p = 0.8, list = FALSE)
```

И разделим выборку согласно вектору `train_rows`:

```{r}
educ_train <- educ_fct[train_rows, ]
educ_test <- educ_fct[-train_rows, ]
```

* Упражнение 1.

Разделите набор данных `Default` из пакета `ISLR` на обучающую и тестовую выборки так,
чтобы в первую попало 70\% всех наблюдений.

```{r}
def <- Default
# glimpse(___)

# train_rows <- createDataPartition(___, p = ___, list = FALSE)
# def_train <- def[___, ]
# def_test <- __[-___, ]
```



# Логистическая регрессия

С помощью метода максимального правдоподобия оценивается модель

\[
y_i =
\begin{cases}
1, \text{ если } y^*_i \geq 0; \\
0, \text{ иначе.}
\end{cases}
\]

\[
y_i^* = \beta_1 + \beta_2 x_i + \beta_3 z_i + u_i,
\]
где $u_i$ имеет специальное логистическое распределение.

Также модель можно записать в виде:

\[
\ln \frac{P(y_i = 1)}{P(y_i = 0)} = \beta_1 + \beta_2 x_i + \beta_3 z_i
\]


Реализуем логистическую регрессию с помощью функции `glm`.
Передадим ей набор данных `educ_train`, формулу и укажем специалный аргумент `family = binomial(link = "logit")`.
Сохраним результаты оценивания в переменную `educ_lmodel` и посмотрим на них.

```{r}
educ_lmodel_glm <- glm(data = educ_train, y ~ gender + SectionID + raisedhands, family = binomial(link = "logit"))
summary(educ_lmodel_glm)
```

- Какие коэффициенты значимы на уровне значимости $\alpha = 0.01$?

* Упражнение 2.

Оцените вероятность не возврата кредита `default` в зависимости от всех остальных
факторов в наборе данных `def`.

```{r}
# def_lmodel_glm <- glm(data = ___, ___ ~ ., family = binomial(link = "___"))
# summary(___)
```


Чтобы найти предельные эффекты, воспользуемся функцией `margins` из одноимённого пакета.
Снова выведем результаты командой `summary()`.

```{r}
educ_margins <- margins(educ_lmodel_glm)
summary(educ_margins)
```

По умолчанию считается средний предельный эффект.
Если нужно подсчитать предельный эффект для конкретного наблюдения,
например, для среднего, то можно воспользоваться опцией `at`.

Предельные эффекты тоже можно визуализировать!
Эта функция реализована в пакете `ggeffects` и называетя `ggpredict`.
Ей нужно передать оценённую модель и указать переменные для визуализации в аргументе `terms`.

```{r, eval=FALSE}
pred_educ_vis <- ggpredict(educ_lmodel_glm, terms = c("raisedhands", "gender"))
pred_educ_vis <- plot(pred_educ_vis)
```

* Упражнение 3.

Оцените предельные эффекты для модели `def_lmodel_glm`.
Визуализируйте предельный эффекта для баланса кредитной карты `balance` отдельно для
студентов `student` и всех остальных.

```{r}
# def_margins <- margins(___)
# summary(___)

# pred_def_vis <- ggpredict(___, terms = c("___", "___"))
# plot(___)
```


Оценивать логистическую модель также можно с помощью пакета `caret`.
Изменения минимальные:

```{r}
educ_lmodel <- train(data = educ_train, y ~ gender + SectionID + raisedhands, family = binomial(link = "logit"), method = "glm")
summary(educ_lmodel)
```

* Упражнение 4.

Оцените заново логистическую регессию по набору данных `def` с помощью функций пакета
`caret`.

```{r}
# def_lmodel <- train(data = ___, default ~ ___, family = binomial(link = "logit"), method = "___")
# summary(___)
```


Посторим прогнозы модели для тестовых данных `educ_test`.
Для этого будем использовать функцию `predict`, которой передадим оценённую модель `educ_lmodel`.
В переменной `educ_predz` уже будут лежать предсказанные классы.
Чтобы получить их вероятности, нужно добавить аргумент `type = "prob"`.

```{r}
educ_pred <- predict(educ_lmodel, newdata = educ_test)
head(educ_pred)

educ_prob <- predict(educ_lmodel, newdata = educ_test, type = "prob")
head(educ_prob)
```

* Упражнение 5.

Постройте прогнозы для тестовой выборки `def_test`.
Сохраните как предсказанные классы, так и их вероятности.

```{r}
# def_pred <- predict(___, newdata = ___)
# head(___)

# def_prob <- predict(___, newdata = ___, type = ___)
# head(___)
```


Теперь мы можем посмотреть на матрицу ошибок и узнать, насколько хорошую модель мы оецнили.
Для этого будем использовть функцию `confusionMatrix` из пакета `caret`.
В качестве аргумента `data` нужно указать предсказанные значения, а в `reference` — правильные ответы.

```{r}
confusionMatrix(data = educ_pred, reference = educ_test$y)
```

* Упражнение 6.

Составьте матрицу ошибок для прогнозов модели `def_lmodel`.

```{r}
# confusionMatrix(data = ___, reference = ___)
```


Чтобы получичть и другие метрики качества для нашей модели, будем использовать функции `twoClassSummary()` и `prSummary()`.
Первая возвращает значения ROC, специфичности и чувствительности.

Чувствительность (полнота) показывает долю правильно распознанных объектов отрицательного класса.
\[
TPR = TP / (TP + FN) = recall = sensitivity
\]

Специфичность показывает долю правильно распознанных объектов положительного класса.
\[
FPR = FP / (FP + TN) = 1 - specificity
\]

ROC — это площадь под кривой, построенной в осях доли правильных положительных ответов и
доли неправильных положительных ответов в зависимости от значения порога для попадания
в положительный класс.

Вторая функция возвращает AUC, полноту, точность и F-меру.

AUC — это площадь под кривой, построенной в осях точность-полнота.
Точность — это доля объектов на самом деле принадлежащих к положительному классу
среди всех объектов, которых модель отнесла к положительному классу.
\[
precision = TP / (TP + FP)
\]

А F-мера — это среднее гармоническое между точностью и полнотой.

Однако обе функции требуют, чтобы во данных были столбцы с вероятностями классов под названиями самих этих классов, истинные ответы под названием `obs`, и бинарные предсказания, названные как `pred`.
Поэтому создадим отдельную таблицу `educ_test_set` со всеми результатами оценивания.

```{r}
educ_test_set <- data.frame(H = educ_prob$H,
                        L = educ_prob$L,
                        pred = educ_pred,
                        obs = educ_test$y)
glimpse(educ_test_set)

twoClassSummary(educ_test_set, lev = levels(educ_test_set$obs)) # don't work with tibble
prSummary(educ_test_set, lev = levels(educ_test_set$obs)) # нужен пакет MLmetrics
```

* Упражнение 7.

Выведите характеристики модели `def_lmodel` с помощью функций `twoClassSummary()` и `prSummary()`.

```{r}
# def_test_set <- data.frame(___ = def_prob$No,
#                            ___ = def_prob$Yes,
#                            pred = ___,
#                            obs = ___)

# twoClassSummary(___, lev = levels(def_test_set$obs))
# prSummary(___, lev = levels(___))
```


Почти все метрики можно визуализировать!
Но для примера мы построим ROC-кривую.
Для этого вдобавок к базовому cлою `ggplot` мы будем использовать слой `geom_roc` из пакета `plotROC`.
В эстетиках нужно указать аргументы `d` — истинные значения — и `m` — метки класса 1.
Если добавить аргумент `color`, то можно получить разные ROC-кривые по категориям какой-нибудь переменной.

```{r}
ggplot(educ_test_set, aes(d = obs, m = L)) +
  geom_roc(n.cuts = 0)

educ_test_set <- mutate(educ_test_set, gender = educ_test$gender)

ggplot(educ_test_set, aes(d = obs, m = L, color = gender)) +
  geom_roc(n.cuts = 0)
```

* Упражнение 8.

Визуализируйте ROC-кривую для прогнозов модели `def_lmodel`.
Сначала общую, а затем отдельно для студентов и всех остальных.

```{r}
# ggplot(___, aes(d = ___, m = Yes)) +
#   geom_roc(n.cuts = 0)

# def_test_set <- mutate(def_test_set, stud = ___)

# ggplot(___, aes(d = ___, m = Yes, color = ___)) +
#   geom_roc(___)
```



# На природу, к деревьям и в лес!

Бинарные деревья очень легко интепретируются при приемлемом качестве прогнозов.

Алгоритмы построения дерева отличаются деталями:

- по какому критерию делить веточку на две?
- когда остановить процесс деления веточек?
- следует ли обрезать дерево после окончания деления?
- как обрабатывать пропущенные значений?

```{r}
tree_model <- train(y ~ . - Class, data = educ_test,
                      method = "rpart2",
                      na.action = na.omit)
```

Картинка дерева:

```{r}
rpart.plot(tree_model$finalModel)
```

Описание дерева:

```{r}
tree_model
```

* Упражнение 9.

Постройте дерево для набора данных `def`, визуализируйте результат и нарисуйте картинку.

```{r}
# def_tree <- train(data = ___, default ~ ., method = "___")
# rpart.plot(___$finalModel)
# summary(___)
```


Предсказываем с помощью дерева на тестовой выборке:

```{r}
educ_tree <- mutate(educ_test,
  yhat = predict(tree_model, educ_test, na.action = na.pass))
confusionMatrix(educ_tree$yhat, educ_tree$y)
```

* Упражнение 10.

Постройте прогнозы с помощью дерева на тестовой выборке `def_test` и
оцените его качество, посмотрев на матрицу ошибок.

```{r}
# def_tree_pred <- mutate(___,
#   yhat = predict(___, ___))
# confusionMatrix(___)
```


Пакет `caret` представляет собой общий интерфейс ко многим моделям,
однако некоторые модели он ещё не поддерживает.
Например, быстрые и стройные, [fast and frugal](https://cran.r-project.org/web/packages/FFTrees/vignettes/FFTrees_heart.html), деревья.

Быстрые деревья нужны, например, в медицине, чтобы
создавать быстрые и простые рекомендации для спасения жизни.

Мы применим их для спасения неуспевающих студентов :)
Увы, пакет принимает на вход только 0/1 в зависимой переменной, поэтому заменим названия категорий на числа:

```{r}
educ_train2 <- mutate(educ_train, ybin = ifelse(y == "H", 1, 0)) %>%
select(-Class)
```

И построим картинку для быстрого и стройного дерева:

```{r}
fftree_model <- FFTrees(formula = ybin ~ .,
                     data = educ_train2)
plot(fftree_model)
```

* Упражнение 11.

Используйте быстрые и стройные деревья для набора данных `def_train`.
Помните, что целевая переменная в нём закодирована как 'Yes' и 'No'.

```{r}
# def_train2 <- mutate(___, defaultbin = ifelse(default == ___))

# def_fftree <- FFTrees(formula = ___ ~ .,
#                       data = ___)
# plot(___)
```


# Случайный лес

В алгоритме случайного леса мы

1. Выращиваем целый лес, скажем 500, деревьев.

2. Строим прогноз с помощью каждого дерева.

3. Агрегируем прогнозы деревьев. Можно в качестве итогового прогноза выбрать ту категорию, за которую проголосовало большинство деревьев. Можно оценить вероятности категорий, взяв процент деревьев, проголосовавших за ту или иную категорию.

Деревья оказываются не идеальными копиями друг друга по двум причинам:

1. Каждое дерево обучается на случайной выборке из исходной выборки. Обычно для каждого дерева берут подвыборку с повторениями из исходной выборки, так чтобы размер подвыборки равнялся размеру исходной выборки.

2. При каждом делении каждой ветки на две части происходит предварительный случайный отбор переменных. Скажем, из исходных 100 переменных, каждый раз случайно отбирается 10, а затем из этих 10 выбирается наилучшая, по которой ветвь и делится на две ветви.

У идеи есть куча вариантов исполнения, отличающихся деталями:

- критерием деления ветви на две;
- критерием остановки деления дерева;
- количеством предварительно отбираемых переменных перед каждым делением;
- количество деревьев;


Посмотрим на все вариации случайного леса, которые перебрал `ranger`.

```{r}
ranger_model <- train(y ~ . - Class, data = educ_test,
                    method = "ranger",
                    na.action = na.omit,
                    importance = "impurity")
ranger_model
plot(ranger_model)
```

И более подробно про наилучшую:

```{r}
ranger_model$finalModel
```

* Упражнение 12.

Реализуйте случайный лес для данных про кредиты,
выведите описание лучешй модели и постройте визуализацию.

```{r}
# def_ranger <- train(___ ~ ., data = ___,
#                     method = "___",
#                     importance = "impurity")
# def_ranger$___
# plot(___)
```


К сожалению, построить информативно про все сотни деревьев невозможно.

Можно попытаться выделить важность переменных:

```{r}
ranger_import <- varImp(ranger_model)
ranger_import
plot(ranger_import)
```


* Упражнение 13.

Выделите важность переменных в модели `def_ranger`.

```{r}
# def_import <- varImp(___)
# def_import
# plot(___)
```

И, конечно, построить прогнозы:

```{r}
educ_ranger <- mutate(educ_test,
  yhat = predict(ranger_model, educ_test, na.action = na.pass))
confusionMatrix(educ_ranger$yhat, educ_ranger$y)
```

По умолчанию, пакет `caret` сам решает, сколько значений параметров перебирать и какие конкретно.

Список перебираемых параметров:

```{r}
modelLookup(model = "ranger")
```


Но мы можем заказать перебор любых.

Можно заказать количество перебираемых значений для каждого параметра:

```{r}
ranger_model <- train(y ~ . - Class, data = educ_test,
                      method = "ranger",
                      na.action = na.omit,
                      importance = "impurity",
                      tuneLength = 4)
```

Или явно значения

```{r}
grid <- expand.grid(mtry = c(5, 10), min.node.size = c(1, 5), splitrule = "gini")

ranger_model <- train(y ~ . - Class, data = educ_test,
            tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model
```



Ура :)
