---
title: 'Семинар 8. Кросс-валидация'
date: 'Ноябрь, 12, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---


Шаманское заклинание для настройки глобальных опций отчёта:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(ISLR) # ещё данные
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
library(ranger) # случайный лес
library(factoextra) # графики для кластеризации и pca
library(elasticnet) # LASSO
library(latex2exp) # формулы в подписях к графику
library(distances) # расчет различных расстояний
```

# Загружаем данные и разбиваем выборку на две части

Снова импортируем набор данных по успеваемости студентов и смотрим на него :)

```{r}
educ <- import("data/xAPI-Edu-Data.csv")
skim(educ)
```

Данные взяты с [kaggle.com](https://www.kaggle.com/aljarah/xAPI-Edu-Data/).
Целевая переменная — успеваемость студента, `Class`, принимает три значения, 'H' (high), 'M' (mid), 'L' (low).
Остальные переменные — характеристики студента.

Повторяем шаги предыдущего семинара:

1. Для целей бинарной классификации объединяем две верхних категории в одну
2. Уберём старую переменную 'Class' с тремя категориями
3. Объявляем все текстовые переменные факторными:

```{r}
educ_logit <- mutate(educ, y = fct_collapse(Class, H = c("M", "H"))) %>%
  select(-Class)
educ_fct <- mutate_if(educ_logit, is.character, factor)
```

По умолчанию, базовой категорией факторной переменной будет категория,
название которой стоит раньше в алфавите.
В нашем примере 'H' идёт в алфавите раньше 'L',
поэтому при построении логистической регрессии категория 'H' будет соответствовать $y_i=0$ в формулах, а категория 'L' — $y_i=1$.
Следовательно, положительный коэффициент
при регрессоре будет означать его положительное влияение на вероятность 'L'.

Конечно, можно не полагаться на алфавит и самому указать любую базовую категорию.

Создадим другую набор данных с альтернативной базовой категорией:

```{r}
educ_fct_rel <- mutate(educ_fct, y = fct_relevel(y, "L"))
```

3. Разбиваем выборку на две части: 80% в обучающей и 20% в тестовой

```{r}
set.seed(777)
train_rows <- createDataPartition(educ_fct$y, p = 0.8, list = FALSE)
educ_train <- educ_fct[train_rows, ]
educ_test <- educ_fct[-train_rows, ]
```


* Упражнение 1.

Разделите набор данных `Default` из пакета `ISLR` на обучающую и тестовую выборки так,
чтобы в первую попало 70\% всех наблюдений.

```{r}
def <- Default
# glimpse(___)
# set.seed(___)
# train_rows <- createDataPartition(___, p = ___, list = FALSE)
# def_train <- def[___, ]
# def_test <- __[-___, ]
```


# Кросс-валидация для LASSO

Чтобы получить простую модель с хорошими предсказаниями, можно использовать LASSO-регрессию.
От обычной она отличается тем, что в целевую функцию мы добавляем дополнительное слагаемое — сумму модулей всех коэффициентов кроме первого:
\[
Q = \sum_{i=1}^n (y_i - \hat y_i)^2 + \lambda \sum_{i=2}^k |\beta_i|,
\]
где $\sum_{i=1}^n (y_i - \hat y_i)^2$ — сумма квадратов остатков,
$\lambda$ — параметр регуляризации.
Добавляя сумму модулей коэффициентов, мы штрафуем модель за слишком большие веса.
При значении параметра $\lambda = 0$ эта модель совпадает с обычным МНК,
а при росте $\lambda$ всё большее число коэффициентов зануляется.

Поcтроим LASSO-регрессию для данных о студентах.
В качестве зависимой переменной возьмём количество раз, когда студент поднимал руку,
а в качестве объясняющих — все остальные.
В параметрах обучения укажем `method = "lasso"` и зададим явно значения параметров, среди которых мы хотим найти наилучший, аргументом `tuneGrid`.

```{r}
set.seed(777)
trctrl <- trainControl(method = "cv", number = 5)
educ_lasso_fit <- train(raisedhands ~ ., data = educ_train,
                        method = "lasso", trControl = trctrl,
                        tuneGrid = expand.grid(.fraction = c(0.1, 0.2, 0.3, 0.5, 0.7)))
educ_lasso_fit
```

```{r}
plot(educ_lasso_fit, xlab = TeX("Доля $R^2$ от МНК"), ylab = "RMSE", main = "LASSO регрессия")
```

* Упражнение 2.

Постройте прогнозы для тестовой выборки.

```{r}
# educ_lasso_pred <- predict(___, newdata = ___)
```




# Случайный лес

В алгоритме случайного леса мы

1. Выращиваем целый лес, скажем 500, деревьев.

2. Строим прогноз с помощью каждого дерева.

3. Агрегируем прогнозы деревьев. Можно в качестве итогового прогноза выбрать ту категорию, за которую проголосовало большинство деревьев. Можно оценить вероятности категорий, взяв процент деревьев, проголосовавших за ту или иную категорию.

Деревья оказываются не идеальными копиями друг друга по двум причинам:

1. Каждое дерево обучается на случайной выборке из исходной выборки. Обычно для каждого дерева берут подвыборку с повторениями из исходной выборки, так чтобы размер подвыборки равнялся размеру исходной выборки.

2. При каждом делении каждой ветки на две части происходит предварительный случайный отбор переменных. Скажем, из исходных 100 переменных, каждый раз случайно отбирается 10, а затем из этих 10 выбирается наилучшая, по которой ветвь и делится на две ветви.

У идеи есть куча вариантов исполнения, отличающихся деталями:

- критерием деления ветви на две;
- критерием остановки деления дерева;
- количеством предварительно отбираемых переменных перед каждым делением;
- количество деревьев;


Посмотрим на все вариации случайного леса, которые перебрал `ranger`.

```{r}
ranger_model <- train(y ~ ., data = educ_train,
                      method = "ranger",
                      na.action = na.omit,
                      importance = "impurity")
ranger_model
plot(ranger_model,
  xlab = "Количество случайно отбираемых регрессоров",
  ylab = "Точность (бутстрэп оценка)",
  main = "Зависимость точности от настроек дерева",
  auto.key = list(title = "Алгоритм разбиения ветки", cex.title = 1))
```

Как мы поняли, что за название легенды отвечает аргумент `auto.key`?

1. Мы проверили класс созданного графика — `trellis`, значит, это `lattice`!
2. Потом загуглили 'lattice change legend title'.
3. Нашли полезную [статью](https://magesblog.com/post/2012-12-04-changing-colours-and-legends-in-lattice/)
4. Профит!

И более подробно про наилучшую:

```{r}
ranger_model$finalModel
```

* Упражнение 3.

Реализуйте случайный лес для данных про кредиты,
выведите описание лучшей модели и постройте визуализацию.

```{r}
# def_ranger <- train(___ ~ ., data = ___,
#                     method = "___",
#                     importance = "impurity")
# def_ranger$___
# plot(___,
# xlab = "Количество случайно отбираемых регрессоров",
# ylab = "Точность (бутстрэп оценка)",
# main = "Зависимость точности от настроек дерева",
# auto.key = list(title = "Алгоритм разбиения ветки", cex.title = 1))
```

Построить информативно на графике все сотни или тысячи деревьев невозможно.

Можно попытаться выделить важность переменных:

```{r}
ranger_import <- varImp(ranger_model)
ranger_import
plot(ranger_import,
    main = "Важность переменных случайного леса",
    xlab = "Среднее падение индекса Джини")
```

* Упражнение 4.

Выделите важность переменных в модели `def_ranger`.

```{r}
# def_import <- varImp(___)
# def_import
# plot(___)
```

И, конечно, построить прогнозы:

```{r}
educ_ranger <- mutate(educ_test,
  yhat = predict(ranger_model, educ_test, na.action = na.pass))
confusionMatrix(educ_ranger$yhat, educ_ranger$y)
```

По умолчанию, пакет `caret` сам решает, сколько значений параметров перебирать и какие конкретно.

Список перебираемых параметров:

```{r}
modelLookup(model = "ranger")
```


Но мы можем заказать перебор любых.

Можно заказать количество перебираемых значений для каждого параметра:

```{r}
ranger_model <- train(y ~ ., data = educ_test,
                      method = "ranger",
                      na.action = na.omit,
                      importance = "impurity",
                      tuneLength = 4)
```

Или явно значения

```{r}
grid <- expand.grid(mtry = c(5, 10), min.node.size = c(1, 5), splitrule = "gini")

ranger_model <- train(y ~ ., data = educ_test,
            tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model
```


# Кросс-валидация для k ближайших соседей

Метод классификации k-ближайших соседей реализует пословицу «Скажи мне, кто твой друг, и я скажу, кто ты».
Мы прогнозируем класс нового наблюдения, как наиболее часто встречающийся класс у ближайших соседей данного наблюдения.


Реализуем метод k ближайших соседей для набора данных про студентов.
Подбирать число соседей будем с помощью кросс-валидации.
Для этого у объекта `trainControl` зададим опции `method = "cv"` и `number = 5`.
Первая отвечает за тип кросс-валидации, а вторая за колиество разбиений выборки.
В настройках обучения `train` укажем метод `knn`, добавим параметры кросс-валидции из объекта `trxrl`, а также попросим центрировать и отмасштабировать данные.

```{r}
trctrl <- trainControl(method = "cv", number = 5)

set.seed(777)
educ_knn_fit <- train(y ~ ., data = educ_train, method = "knn",
                      trControl = trctrl,
                      preProcess = c("center", "scale"))

educ_knn_fit
```

Визуализируем долю правильных ответов в зависимости от числа соседей.

```{r}
plot(educ_knn_fit, xlab = "Число соседей",
     ylab = "Доля правильных ответов",
     main = "Метод k ближаших соседей")
```

* Упражнение 5.

Реализуйте метод k ближайших соседей на данных о кредитах.
Не забудьте центрировать и отмасштабировать их!
Затем визуализрйуте полученный результат.

```{r}
# def_knn_fit <- train(___ ~ ., data = ___, method = "___",
#                      trControl = trctrl,
#                      preProcess = c("___", "___"))

# plot(___, xlab = "Число соседей",
#      ylab = "Доля правильных ответов",
#      main = "Метод k ближаших соседей")
```


Теперь получим прогнозы для тестовой выборки и оценим их качество.

```{r}
educ_knn_predict <- predict(educ_knn_fit, newdata = educ_test)
confusionMatrix(educ_knn_predict, educ_test$y)
```

* Упражнение 6.

Постройте прогнозы метода k ближайших соседей для данных по кредитам и оцените их качество.

```{r}
# def_knn_pred <- predict(___, newdata = ___)
# confusionMatrix(___, ___$default)
```



# ROC-кривая и логистическая регрессия

Оцениваем логистическую регрессию с помощью пакета `caret`.

```{r}
educ_lmodel <- train(data = educ_train,
  y ~ gender + SectionID + raisedhands, family = binomial(link = "logit"),
  method = "glm")
summary(educ_lmodel)
```

* Упражнение 7.

Оцените заново логистическую регессию по набору данных `def` с помощью функций пакета
`caret`.

```{r}
# def_lmodel <- train(data = ___, default ~ ___, family = binomial(link = "logit"), method = "___")
# summary(___)
```


Посторим прогнозы модели для тестовых данных `educ_test`.
Для этого будем использовать функцию `predict`, которой передадим оценённую модель `educ_lmodel`.
В переменной `educ_predz` уже будут лежать предсказанные классы.
Чтобы получить их вероятности, нужно добавить аргумент `type = "prob"`.

```{r}
educ_pred <- predict(educ_lmodel, newdata = educ_test)
head(educ_pred)

educ_prob <- predict(educ_lmodel, newdata = educ_test, type = "prob")
head(educ_prob)
```

* Упражнение 8.

Постройте прогнозы для тестовой выборки `def_test`.
Сохраните как предсказанные классы, так и их вероятности.

```{r}
# def_pred <- predict(___, newdata = ___)
# head(___)

# def_prob <- predict(___, newdata = ___, type = ___)
# head(___)
```


Теперь мы можем посмотреть на матрицу ошибок и узнать, насколько хорошую модель мы оценили.
Для этого будем использовть функцию `confusionMatrix` из пакета `caret`.
В качестве аргумента `data` нужно указать предсказанные значения, а в `reference` — правильные ответы.

```{r}
confusionMatrix(data = educ_pred, reference = educ_test$y)
```

* Упражнение 9.

Составьте матрицу ошибок для прогнозов модели `def_lmodel`.

```{r}
# confusionMatrix(data = ___, reference = ___)
```


Чтобы получичть и другие метрики качества для нашей модели, будем использовать функции `twoClassSummary()` и `prSummary()`.
Первая возвращает значения ROC, специфичности и чувствительности.

Чувствительность (полнота) показывает долю правильно распознанных объектов отрицательного класса.
\[
TPR = TP / (TP + FN) = recall = sensitivity
\]

Специфичность показывает долю правильно распознанных объектов положительного класса.
\[
FPR = FP / (FP + TN) = 1 - specificity
\]

ROC — это площадь под кривой, построенной в осях доли правильных положительных ответов и
доли неправильных положительных ответов в зависимости от значения порога для попадания
в положительный класс.

Вторая функция возвращает AUC, полноту, точность и F-меру.

AUC — это площадь под кривой, построенной в осях точность-полнота.
Точность — это доля объектов на самом деле принадлежащих к положительному классу
среди всех объектов, которых модель отнесла к положительному классу.
\[
precision = TP / (TP + FP)
\]

А F-мера — это среднее гармоническое между точностью и полнотой.

Однако обе функции требуют, чтобы в данных были столбцы с вероятностями классов под названиями самих этих классов, истинные ответы под названием `obs`, и бинарные предсказания, названные `pred`.
Поэтому создадим отдельную таблицу `educ_test_set` со всеми результатами оценивания.

```{r}
educ_test_set <- data.frame(H = educ_prob$H,
                            L = educ_prob$L,
                            pred = educ_pred,
                            obs = educ_test$y)
glimpse(educ_test_set)

levs <- levels(educ_test_set$obs)

twoClassSummary(educ_test_set, lev = levs) # don't work with tibble
prSummary(educ_test_set, lev = levs) # нужен пакет MLmetrics
```

- Что находится в векторе `levs`?


* Упражнение 10.

Выведите характеристики модели `def_lmodel` с помощью функций `twoClassSummary()` и `prSummary()`.

```{r}
# def_test_set <- data.frame(___ = def_prob$No,
#                            ___ = def_prob$Yes,
#                            pred = ___,
#                            obs = ___)

# twoClassSummary(___, lev = levels(def_test_set$obs))
# prSummary(___, lev = levels(___))
```


Почти все метрики можно визуализировать!
Но для примера мы построим ROC-кривую.
Для этого вдобавок к базовому слою `ggplot` мы будем использовать слой `geom_roc` из пакета `plotROC`.
В эстетиках нужно указать аргументы `d` — истинные значения — и `m` — метки положительного класса.
Если добавить аргумент `color`, то можно получить разные ROC-кривые по категориям какой-нибудь переменной.

```{r}
ggplot(educ_test_set, aes(d = obs, m = L)) +
  geom_roc(n.cuts = 0) +
  labs(title = "Кривая ROC",
       x = "False positive ratio = FP / (FP + TN)",
       y = "True positive ratio = TP / (TP + FN)")

educ_test_set <- mutate(educ_test_set, gender = educ_test$gender)

ggplot(educ_test_set, aes(d = obs, m = L, color = gender)) +
  geom_roc(n.cuts = 0) +
  labs(title = "Кривые ROC в зависимости от пола",
       x = "False positive ratio = FP / (FP + TN)",
       y = "True positive ratio = TP / (TP + FN)",
       color = "Пол")
```

* Упражнение 11.

Визуализируйте ROC-кривую для прогнозов модели `def_lmodel`.
Сначала общую, а затем отдельно для студентов и всех остальных.

```{r}
# ggplot(___, aes(d = ___, m = Yes)) +
#   geom_roc(n.cuts = 0)

# def_test_set <- mutate(def_test_set, stud = ___)

# ggplot(___, aes(d = ___, m = Yes, color = ___)) +
#   geom_roc(___)
```




Ура :)
